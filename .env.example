# .env.example - Template for environment variables
# Copy this file to .env and fill in your actual values

# =============================================================================
# SECURITY & AUTHENTICATION
# =============================================================================
SECRET_KEY=your-super-secret-flask-key-change-this-in-production
JWT_SECRET_KEY=your-jwt-secret-key-for-token-signing
ENCRYPTION_KEY=your-encryption-key-for-sensitive-data

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
FLASK_ENV=production
LOG_LEVEL=INFO
WEB_PORT=5000

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
# PostgreSQL Settings
POSTGRES_USER=breakout_user
POSTGRES_PASSWORD=secure_database_password_change_this
POSTGRES_DB=breakout_db
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# Full Database URL (auto-generated from above or override)
DATABASE_URL=postgresql://breakout_user:secure_database_password_change_this@postgres:5432/breakout_db

# =============================================================================
# REDIS & CACHING
# =============================================================================
REDIS_PASSWORD=secure_redis_password_change_this
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0

# Full Redis URL (auto-generated from above or override)
REDIS_URL=redis://:secure_redis_password_change_this@redis:6379/0

# =============================================================================
# CELERY BACKGROUND PROCESSING
# =============================================================================
CELERY_BROKER_URL=redis://:secure_redis_password_change_this@redis:6379/0
CELERY_RESULT_BACKEND=redis://:secure_redis_password_change_this@redis:6379/1
CELERY_WORKERS=2

# =============================================================================
# MARKET DATA API KEYS
# =============================================================================
# TwelveData API (Free tier: 800 requests/day)
TWELVEDATA_API_KEY=your_twelvedata_api_key_here

# Alpha Vantage API (Free tier: 5 requests/minute, 500/day)
ALPHAVANTAGE_API_KEY=your_alphavantage_api_key_here

# Yahoo Finance (backup - no key required but rate limited)
YFINANCE_ENABLED=true

# =============================================================================
# ML MODEL CONFIGURATION
# =============================================================================
# Optuna hyperparameter optimization
OPTUNA_N_TRIALS_XGB=100
OPTUNA_N_TRIALS_LSTM=50
OPTUNA_TIMEOUT=1800

# Training limits
MAX_TRAINING_TIME=3600
MODEL_CACHE_TTL=3600

# =============================================================================
# MONITORING & OBSERVABILITY
# =============================================================================
PROMETHEUS_METRICS_ENABLED=true
PROMETHEUS_PORT=9090

# Grafana (if using)
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=secure_grafana_password_change_this
GRAFANA_PORT=3001

# =============================================================================
# CLOUD STORAGE (Optional)
# =============================================================================
# Google Cloud Storage for model artifacts
GCS_BUCKET_NAME=your-breakout-models-bucket
GCS_PROJECT_ID=your-gcp-project-id
GOOGLE_APPLICATION_CREDENTIALS=path/to/service-account-key.json

# MLflow tracking (if using)
MLFLOW_TRACKING_URI=http://localhost:5001
MLFLOW_EXPERIMENT_NAME=BreakoutPrediction

# =============================================================================
# RATE LIMITING & SECURITY
# =============================================================================
API_RATE_LIMIT=100/hour
TRAINING_RATE_LIMIT=10/hour
MAX_DATAFRAME_SIZE=1000000

# Allowed tickers (comma-separated, leave empty for no restriction)
ALLOWED_TICKERS=

# =============================================================================
# SYSTEM CONFIGURATION
# =============================================================================
# Paths (relative to application root)
MODELS_PATH=./models
DATA_CACHE_PATH=./data_cache
LOGS_PATH=./logs
PREDICTIONS_PATH=./predictions

# Breakout detection parameters
MIN_CONSOLIDATION_DAYS=10
MAX_CONSOLIDATION_DAYS=120
TARGET_BREAKOUT_MAGNITUDE=0.40
BREAKOUT_WINDOW_DAYS=60

# Market cap filters (USD)
MIN_MARKET_CAP=300000000
MAX_MARKET_CAP=2000000000

# =============================================================================
# DEVELOPMENT/DEBUG SETTINGS
# =============================================================================
DEBUG=false
TESTING=false
AUDIT_LOG_ENABLED=true
PERFORMANCE_PROFILING=false

# =============================================================================
# ENTERPRISE FEATURE STORE
# =============================================================================
# ClickHouse (Time-series storage)
CLICKHOUSE_HOST=localhost
CLICKHOUSE_PORT=8123
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD=
CLICKHOUSE_DATABASE=feature_store

# Redis Cluster (High-performance caching)
REDIS_CLUSTER_NODES=localhost:7000,localhost:7001,localhost:7002
REDIS_CLUSTER_PASSWORD=your_cluster_password

# Kafka (Real-time streaming)
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_FEATURE_TOPIC=market_features
KAFKA_PREDICTION_TOPIC=breakout_predictions

# Dask (Distributed computing)
DASK_SCHEDULER_HOST=localhost
DASK_SCHEDULER_PORT=8786

# Feature Store Configuration
FEATURE_STORE_USE_GPU=false
FEATURE_STORE_MAX_WORKERS=10
FEATURE_STORE_COMPRESSION=true
FEATURE_STORE_CACHE_TTL=3600

# Feature Drift Monitoring
DRIFT_DETECTION_ENABLED=true
DRIFT_THRESHOLD_HIGH=0.7
DRIFT_THRESHOLD_MEDIUM=0.5
DRIFT_THRESHOLD_LOW=0.3

# Vector Store (Optional)
VECTOR_STORE_DIMENSION=128
VECTOR_STORE_ENABLED=true

# =============================================================================
# BACKUP & RECOVERY
# =============================================================================
BACKUP_ENABLED=true
BACKUP_RETENTION_DAYS=30
BACKUP_SCHEDULE="0 2 * * *"  # Daily at 2 AM